{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "source_dirs = [\"/shared/ds/apps/DSpackages/segmentation_models.pytorch\"]\n",
    "working_dir = \"/shared/ds/data/compvis/maize/PLTQR_explainable/\"\n",
    "model_dir = os.path.join(working_dir, \"models\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "from torchinfo import summary\n",
    "\n",
    "sys.path.extend(source_dirs)\n",
    "import segmentation_models_pytorch as smp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [],
   "source": [
    "model_resnet18 = smp.Unet(\n",
    "    encoder_name=\"resnet18\",  # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",  # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=1,  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=3,  # model output channels (number of classes in your dataset)\n",
    "\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n",
      "ResNetEncoder(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "modules = [m  for m in model_resnet18.modules()]\n",
    "print(len(modules))\n",
    "\n",
    "print(modules[1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n"
     ]
    }
   ],
   "source": [
    "print(len(modules))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = model_resnet18.encoder.conv1(torch.randn(1, 1, 576, 576))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 288, 288])\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_resnet18.encoder.conv1(torch.randn(1, 1, 576, 576))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=160, out_features=5, bias=True)\n",
      "------------Input Grad------------\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "------------Output Grad------------\n",
      "torch.Size([5])\n",
      "tensor([-0.2000, -0.2000, -0.2000, -0.2000, -0.2000])\n",
      "\n",
      "\n",
      "Conv2d(3, 10, kernel_size=(2, 2), stride=(2, 2))\n",
      "------------Input Grad------------\n",
      "None found for Gradient\n",
      "torch.Size([10, 3, 2, 2])\n",
      "torch.Size([10])\n",
      "------------Output Grad------------\n",
      "torch.Size([1, 10, 4, 4])\n",
      "tensor([[[[ 0.0000,  0.0349,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000, -0.0153],\n",
      "          [ 0.0000, -0.0024,  0.0041,  0.0000],\n",
      "          [ 0.0084, -0.0032,  0.0000,  0.0288]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0077, -0.0091],\n",
      "          [ 0.0000,  0.0000,  0.0032,  0.0000],\n",
      "          [-0.0081,  0.0000,  0.0000,  0.0162],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.0230,  0.0222,  0.0000, -0.0021],\n",
      "          [ 0.0166,  0.0170, -0.0316,  0.0000],\n",
      "          [-0.0171,  0.0000,  0.0391,  0.0116],\n",
      "          [ 0.0000,  0.0000, -0.0415,  0.0000]],\n",
      "\n",
      "         [[-0.0164, -0.0165, -0.0243, -0.0180],\n",
      "          [-0.0195,  0.0202,  0.0007,  0.0000],\n",
      "          [ 0.0261,  0.0000,  0.0013,  0.0000],\n",
      "          [-0.0180,  0.0067, -0.0081,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  0.0150],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0100,  0.0000,  0.0000, -0.0075],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0056]],\n",
      "\n",
      "         [[ 0.0000, -0.0285,  0.0022,  0.0086],\n",
      "          [-0.0540,  0.0000,  0.0115,  0.0000],\n",
      "          [-0.0139,  0.0357,  0.0216,  0.0002],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0208,  0.0020,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0427,  0.0000],\n",
      "          [ 0.0120,  0.0070,  0.0000, -0.0184]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [-0.0211,  0.0000,  0.0000, -0.0093],\n",
      "          [ 0.0002,  0.0049,  0.0000, -0.0335]],\n",
      "\n",
      "         [[ 0.0029,  0.0000,  0.0218,  0.0163],\n",
      "          [ 0.0148, -0.0072, -0.0197,  0.0048],\n",
      "          [-0.0222,  0.0000,  0.0000, -0.0393],\n",
      "          [-0.0271,  0.0000, -0.0217,  0.0002]],\n",
      "\n",
      "         [[-0.0116,  0.0133,  0.0000,  0.0000],\n",
      "          [-0.0017,  0.0000,  0.0000,  0.0000],\n",
      "          [-0.0075,  0.0000, -0.0291,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000, -0.0012]]]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class myNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv = nn.Conv2d(3,10,2, stride = 2)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.flatten = lambda x: x.view(-1)\n",
    "    self.fc1 = nn.Linear(160,5)\n",
    "  def forward(self, x):\n",
    "    x = self.relu(self.conv(x))\n",
    "    return self.fc1(self.flatten(x))\n",
    "\n",
    "net = myNet()\n",
    "\n",
    "def hook_fn(m, i, o):\n",
    "  print(m)\n",
    "  print(\"------------Input Grad------------\")\n",
    "  for grad in i:\n",
    "    try:\n",
    "      print(grad.shape)\n",
    "    except AttributeError:\n",
    "      print (\"None found for Gradient\")\n",
    "\n",
    "  print(\"------------Output Grad------------\")\n",
    "  for grad in o:\n",
    "    try:\n",
    "      print(grad.shape)\n",
    "      print(grad)\n",
    "    except AttributeError:\n",
    "      print (\"None found for Gradient\")\n",
    "  print(\"\\n\")\n",
    "net.conv.register_backward_hook(hook_fn)\n",
    "net.fc1.register_backward_hook(hook_fn)\n",
    "inp = torch.randn(1,3,8,8)\n",
    "out = net(inp)\n",
    "\n",
    "(1 - out.mean()).backward()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "aaaa = None\n",
    "names, modules= [], []\n",
    "for ii, (name, module) in enumerate(model_resnet18.named_modules()):\n",
    "    #print(ii,aa)\n",
    "    names.append(name)\n",
    "    modules.append(module)\n",
    "\n",
    "    if ii == 104:\n",
    "        aaaa = module\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "['',\n 'encoder',\n 'encoder.conv1',\n 'encoder.bn1',\n 'encoder.relu',\n 'encoder.maxpool',\n 'encoder.layer1',\n 'encoder.layer1.0',\n 'encoder.layer1.0.conv1',\n 'encoder.layer1.0.bn1',\n 'encoder.layer1.0.relu',\n 'encoder.layer1.0.conv2',\n 'encoder.layer1.0.bn2',\n 'encoder.layer1.1',\n 'encoder.layer1.1.conv1',\n 'encoder.layer1.1.bn1',\n 'encoder.layer1.1.relu',\n 'encoder.layer1.1.conv2',\n 'encoder.layer1.1.bn2',\n 'encoder.layer2',\n 'encoder.layer2.0',\n 'encoder.layer2.0.conv1',\n 'encoder.layer2.0.bn1',\n 'encoder.layer2.0.relu',\n 'encoder.layer2.0.conv2',\n 'encoder.layer2.0.bn2',\n 'encoder.layer2.0.downsample',\n 'encoder.layer2.0.downsample.0',\n 'encoder.layer2.0.downsample.1',\n 'encoder.layer2.1',\n 'encoder.layer2.1.conv1',\n 'encoder.layer2.1.bn1',\n 'encoder.layer2.1.relu',\n 'encoder.layer2.1.conv2',\n 'encoder.layer2.1.bn2',\n 'encoder.layer3',\n 'encoder.layer3.0',\n 'encoder.layer3.0.conv1',\n 'encoder.layer3.0.bn1',\n 'encoder.layer3.0.relu',\n 'encoder.layer3.0.conv2',\n 'encoder.layer3.0.bn2',\n 'encoder.layer3.0.downsample',\n 'encoder.layer3.0.downsample.0',\n 'encoder.layer3.0.downsample.1',\n 'encoder.layer3.1',\n 'encoder.layer3.1.conv1',\n 'encoder.layer3.1.bn1',\n 'encoder.layer3.1.relu',\n 'encoder.layer3.1.conv2',\n 'encoder.layer3.1.bn2',\n 'encoder.layer4',\n 'encoder.layer4.0',\n 'encoder.layer4.0.conv1',\n 'encoder.layer4.0.bn1',\n 'encoder.layer4.0.relu',\n 'encoder.layer4.0.conv2',\n 'encoder.layer4.0.bn2',\n 'encoder.layer4.0.downsample',\n 'encoder.layer4.0.downsample.0',\n 'encoder.layer4.0.downsample.1',\n 'encoder.layer4.1',\n 'encoder.layer4.1.conv1',\n 'encoder.layer4.1.bn1',\n 'encoder.layer4.1.relu',\n 'encoder.layer4.1.conv2',\n 'encoder.layer4.1.bn2',\n 'decoder',\n 'decoder.center',\n 'decoder.blocks',\n 'decoder.blocks.0',\n 'decoder.blocks.0.conv1',\n 'decoder.blocks.0.conv1.0',\n 'decoder.blocks.0.conv1.1',\n 'decoder.blocks.0.conv1.2',\n 'decoder.blocks.0.attention1',\n 'decoder.blocks.0.attention1.attention',\n 'decoder.blocks.0.conv2',\n 'decoder.blocks.0.conv2.0',\n 'decoder.blocks.0.conv2.1',\n 'decoder.blocks.0.conv2.2',\n 'decoder.blocks.0.attention2',\n 'decoder.blocks.0.attention2.attention',\n 'decoder.blocks.1',\n 'decoder.blocks.1.conv1',\n 'decoder.blocks.1.conv1.0',\n 'decoder.blocks.1.conv1.1',\n 'decoder.blocks.1.conv1.2',\n 'decoder.blocks.1.attention1',\n 'decoder.blocks.1.attention1.attention',\n 'decoder.blocks.1.conv2',\n 'decoder.blocks.1.conv2.0',\n 'decoder.blocks.1.conv2.1',\n 'decoder.blocks.1.conv2.2',\n 'decoder.blocks.1.attention2',\n 'decoder.blocks.1.attention2.attention',\n 'decoder.blocks.2',\n 'decoder.blocks.2.conv1',\n 'decoder.blocks.2.conv1.0',\n 'decoder.blocks.2.conv1.1',\n 'decoder.blocks.2.conv1.2',\n 'decoder.blocks.2.attention1',\n 'decoder.blocks.2.attention1.attention',\n 'decoder.blocks.2.conv2',\n 'decoder.blocks.2.conv2.0',\n 'decoder.blocks.2.conv2.1',\n 'decoder.blocks.2.conv2.2',\n 'decoder.blocks.2.attention2',\n 'decoder.blocks.2.attention2.attention',\n 'decoder.blocks.3',\n 'decoder.blocks.3.conv1',\n 'decoder.blocks.3.conv1.0',\n 'decoder.blocks.3.conv1.1',\n 'decoder.blocks.3.conv1.2',\n 'decoder.blocks.3.attention1',\n 'decoder.blocks.3.attention1.attention',\n 'decoder.blocks.3.conv2',\n 'decoder.blocks.3.conv2.0',\n 'decoder.blocks.3.conv2.1',\n 'decoder.blocks.3.conv2.2',\n 'decoder.blocks.3.attention2',\n 'decoder.blocks.3.attention2.attention',\n 'decoder.blocks.4',\n 'decoder.blocks.4.conv1',\n 'decoder.blocks.4.conv1.0',\n 'decoder.blocks.4.conv1.1',\n 'decoder.blocks.4.conv1.2',\n 'decoder.blocks.4.attention1',\n 'decoder.blocks.4.attention1.attention',\n 'decoder.blocks.4.conv2',\n 'decoder.blocks.4.conv2.0',\n 'decoder.blocks.4.conv2.1',\n 'decoder.blocks.4.conv2.2',\n 'decoder.blocks.4.attention2',\n 'decoder.blocks.4.attention2.attention',\n 'segmentation_head',\n 'segmentation_head.0',\n 'segmentation_head.1',\n 'segmentation_head.2',\n 'segmentation_head.2.activation']"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "data": {
      "text/plain": "['__call__',\n '__class__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattr__',\n '__getattribute__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__setstate__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n '_apply',\n '_backward_hooks',\n '_buffers',\n '_forward_hooks',\n '_forward_pre_hooks',\n '_get_name',\n '_load_from_state_dict',\n '_load_state_dict_pre_hooks',\n '_modules',\n '_named_members',\n '_parameters',\n '_register_load_state_dict_pre_hook',\n '_register_state_dict_hook',\n '_replicate_for_data_parallel',\n '_save_to_state_dict',\n '_slow_forward',\n '_state_dict_hooks',\n '_version',\n 'add_module',\n 'apply',\n 'bfloat16',\n 'buffers',\n 'check_input_shape',\n 'children',\n 'classification_head',\n 'cpu',\n 'cuda',\n 'decoder',\n 'double',\n 'dump_patches',\n 'encoder',\n 'eval',\n 'extra_repr',\n 'float',\n 'forward',\n 'half',\n 'initialize',\n 'load_state_dict',\n 'modules',\n 'name',\n 'named_buffers',\n 'named_children',\n 'named_modules',\n 'named_parameters',\n 'parameters',\n 'predict',\n 'register_backward_hook',\n 'register_buffer',\n 'register_forward_hook',\n 'register_forward_pre_hook',\n 'register_parameter',\n 'requires_grad_',\n 'segmentation_head',\n 'share_memory',\n 'state_dict',\n 'to',\n 'train',\n 'training',\n 'type',\n 'zero_grad']"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(modules[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.named_children of Unet(\n",
      "  (encoder): ResNetEncoder(\n",
      "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): UnetDecoder(\n",
      "    (center): Identity()\n",
      "    (blocks): ModuleList(\n",
      "      (0): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (4): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (segmentation_head): SegmentationHead(\n",
      "    (0): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Identity()\n",
      "    (2): Activation(\n",
      "      (activation): Identity()\n",
      "    )\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(modules[1].named_children)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "140"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(names))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "encoder\n",
      "encoder.conv1\n",
      "encoder.bn1\n",
      "encoder.relu\n",
      "encoder.maxpool\n",
      "encoder.layer1\n",
      "encoder.layer1.0\n",
      "encoder.layer1.0.conv1\n",
      "encoder.layer1.0.bn1\n",
      "encoder.layer1.0.relu\n",
      "encoder.layer1.0.conv2\n",
      "encoder.layer1.0.bn2\n",
      "encoder.layer1.1\n",
      "encoder.layer1.1.conv1\n",
      "encoder.layer1.1.bn1\n",
      "encoder.layer1.1.relu\n",
      "encoder.layer1.1.conv2\n",
      "encoder.layer1.1.bn2\n",
      "encoder.layer2\n",
      "encoder.layer2.0\n",
      "encoder.layer2.0.conv1\n",
      "encoder.layer2.0.bn1\n",
      "encoder.layer2.0.relu\n",
      "encoder.layer2.0.conv2\n",
      "encoder.layer2.0.bn2\n",
      "encoder.layer2.0.downsample\n",
      "encoder.layer2.0.downsample.0\n",
      "encoder.layer2.0.downsample.1\n",
      "encoder.layer2.1\n",
      "encoder.layer2.1.conv1\n",
      "encoder.layer2.1.bn1\n",
      "encoder.layer2.1.relu\n",
      "encoder.layer2.1.conv2\n",
      "encoder.layer2.1.bn2\n",
      "encoder.layer3\n",
      "encoder.layer3.0\n",
      "encoder.layer3.0.conv1\n",
      "encoder.layer3.0.bn1\n",
      "encoder.layer3.0.relu\n",
      "encoder.layer3.0.conv2\n",
      "encoder.layer3.0.bn2\n",
      "encoder.layer3.0.downsample\n",
      "encoder.layer3.0.downsample.0\n",
      "encoder.layer3.0.downsample.1\n",
      "encoder.layer3.1\n",
      "encoder.layer3.1.conv1\n",
      "encoder.layer3.1.bn1\n",
      "encoder.layer3.1.relu\n",
      "encoder.layer3.1.conv2\n",
      "encoder.layer3.1.bn2\n",
      "encoder.layer4\n",
      "encoder.layer4.0\n",
      "encoder.layer4.0.conv1\n",
      "encoder.layer4.0.bn1\n",
      "encoder.layer4.0.relu\n",
      "encoder.layer4.0.conv2\n",
      "encoder.layer4.0.bn2\n",
      "encoder.layer4.0.downsample\n",
      "encoder.layer4.0.downsample.0\n",
      "encoder.layer4.0.downsample.1\n",
      "encoder.layer4.1\n",
      "encoder.layer4.1.conv1\n",
      "encoder.layer4.1.bn1\n",
      "encoder.layer4.1.relu\n",
      "encoder.layer4.1.conv2\n",
      "encoder.layer4.1.bn2\n",
      "decoder\n",
      "decoder.center\n",
      "decoder.blocks\n",
      "decoder.blocks.0\n",
      "decoder.blocks.0.conv1\n",
      "decoder.blocks.0.conv1.0\n",
      "decoder.blocks.0.conv1.1\n",
      "decoder.blocks.0.conv1.2\n",
      "decoder.blocks.0.attention1\n",
      "decoder.blocks.0.attention1.attention\n",
      "decoder.blocks.0.conv2\n",
      "decoder.blocks.0.conv2.0\n",
      "decoder.blocks.0.conv2.1\n",
      "decoder.blocks.0.conv2.2\n",
      "decoder.blocks.0.attention2\n",
      "decoder.blocks.0.attention2.attention\n",
      "decoder.blocks.1\n",
      "decoder.blocks.1.conv1\n",
      "decoder.blocks.1.conv1.0\n",
      "decoder.blocks.1.conv1.1\n",
      "decoder.blocks.1.conv1.2\n",
      "decoder.blocks.1.attention1\n",
      "decoder.blocks.1.attention1.attention\n",
      "decoder.blocks.1.conv2\n",
      "decoder.blocks.1.conv2.0\n",
      "decoder.blocks.1.conv2.1\n",
      "decoder.blocks.1.conv2.2\n",
      "decoder.blocks.1.attention2\n",
      "decoder.blocks.1.attention2.attention\n",
      "decoder.blocks.2\n",
      "decoder.blocks.2.conv1\n",
      "decoder.blocks.2.conv1.0\n",
      "decoder.blocks.2.conv1.1\n",
      "decoder.blocks.2.conv1.2\n",
      "decoder.blocks.2.attention1\n",
      "decoder.blocks.2.attention1.attention\n",
      "decoder.blocks.2.conv2\n",
      "decoder.blocks.2.conv2.0\n",
      "decoder.blocks.2.conv2.1\n",
      "decoder.blocks.2.conv2.2\n",
      "decoder.blocks.2.attention2\n",
      "decoder.blocks.2.attention2.attention\n",
      "decoder.blocks.3\n",
      "decoder.blocks.3.conv1\n",
      "decoder.blocks.3.conv1.0\n",
      "decoder.blocks.3.conv1.1\n",
      "decoder.blocks.3.conv1.2\n",
      "decoder.blocks.3.attention1\n",
      "decoder.blocks.3.attention1.attention\n",
      "decoder.blocks.3.conv2\n",
      "decoder.blocks.3.conv2.0\n",
      "decoder.blocks.3.conv2.1\n",
      "decoder.blocks.3.conv2.2\n",
      "decoder.blocks.3.attention2\n",
      "decoder.blocks.3.attention2.attention\n",
      "decoder.blocks.4\n",
      "decoder.blocks.4.conv1\n",
      "decoder.blocks.4.conv1.0\n",
      "decoder.blocks.4.conv1.1\n",
      "decoder.blocks.4.conv1.2\n",
      "decoder.blocks.4.attention1\n",
      "decoder.blocks.4.attention1.attention\n",
      "decoder.blocks.4.conv2\n",
      "decoder.blocks.4.conv2.0\n",
      "decoder.blocks.4.conv2.1\n",
      "decoder.blocks.4.conv2.2\n",
      "decoder.blocks.4.attention2\n",
      "decoder.blocks.4.attention2.attention\n",
      "segmentation_head\n",
      "segmentation_head.0\n",
      "segmentation_head.1\n",
      "segmentation_head.2\n",
      "segmentation_head.2.activation\n"
     ]
    }
   ],
   "source": [
    "model_resnet18 = smp.Unet(\n",
    "    encoder_name=\"resnet18\",  # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",  # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=1,  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=3,  # model output channels (number of classes in your dataset)\n",
    "\n",
    ")\n",
    "net = model_resnet18\n",
    "visualisation = []\n",
    "\n",
    "def hook_fn(m, i, o):\n",
    "  visualisation.append((m.nv_name,m, o))\n",
    "  #visualisation[m] = o\n",
    "\n",
    "def get_all_layers(net):\n",
    "  for name, layer in net.named_modules():\n",
    "    #print(name)\n",
    "    #print(type(layer))\n",
    "    #If it is a sequential, don't register a hook on it\n",
    "    # but recursively register hook on all it's module children\n",
    "    if 1==1: # if not isinstance(layer, nn.Sequential):\n",
    "    #  get_all_layers(layer)\n",
    "    #else:\n",
    "      # it's a non sequential. Register a hook\n",
    "        print(name)\n",
    "        layer.nv_name=name\n",
    "        layer.register_forward_hook(hook_fn)\n",
    "\n",
    "\n",
    "get_all_layers(net)\n",
    "\n",
    "\n",
    "out = net(torch.randn(1, 1, 576, 576))\n",
    "\n",
    "# Just to check whether we got all layers\n",
    "#visualisation.keys()      #output includes sequential layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "outputs": [],
   "source": [
    "class VerboseExecution(nn.Module):\n",
    "    def __init__(self, model: nn.Module):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "        # Register a hook for each layer\n",
    "        for name, layer in self.model.named_modules():\n",
    "            layer.__name__ = name\n",
    "            layer.register_forward_hook(\n",
    "                lambda layer, _, output: print(f\"{layer.__name__}: {output.shape} \" if hasattr(output,'shape') else f\"{layer.__name__}: NO SHAPE\" )\n",
    "            )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.conv1: torch.Size([1, 64, 288, 288]) \n",
      "encoder.bn1: torch.Size([1, 64, 288, 288]) \n",
      "encoder.relu: torch.Size([1, 64, 288, 288]) \n",
      "encoder.maxpool: torch.Size([1, 64, 144, 144]) \n",
      "encoder.layer1.0.conv1: torch.Size([1, 64, 144, 144]) \n",
      "encoder.layer1.0.bn1: torch.Size([1, 64, 144, 144]) \n",
      "encoder.layer1.0.relu: torch.Size([1, 64, 144, 144]) \n",
      "encoder.layer1.0.conv2: torch.Size([1, 64, 144, 144]) \n",
      "encoder.layer1.0.bn2: torch.Size([1, 64, 144, 144]) \n",
      "encoder.layer1.0.relu: torch.Size([1, 64, 144, 144]) \n",
      "encoder.layer1.0: torch.Size([1, 64, 144, 144]) \n",
      "encoder.layer1.1.conv1: torch.Size([1, 64, 144, 144]) \n",
      "encoder.layer1.1.bn1: torch.Size([1, 64, 144, 144]) \n",
      "encoder.layer1.1.relu: torch.Size([1, 64, 144, 144]) \n",
      "encoder.layer1.1.conv2: torch.Size([1, 64, 144, 144]) \n",
      "encoder.layer1.1.bn2: torch.Size([1, 64, 144, 144]) \n",
      "encoder.layer1.1.relu: torch.Size([1, 64, 144, 144]) \n",
      "encoder.layer1.1: torch.Size([1, 64, 144, 144]) \n",
      "encoder.layer1: torch.Size([1, 64, 144, 144]) \n",
      "encoder.layer2.0.conv1: torch.Size([1, 128, 72, 72]) \n",
      "encoder.layer2.0.bn1: torch.Size([1, 128, 72, 72]) \n",
      "encoder.layer2.0.relu: torch.Size([1, 128, 72, 72]) \n",
      "encoder.layer2.0.conv2: torch.Size([1, 128, 72, 72]) \n",
      "encoder.layer2.0.bn2: torch.Size([1, 128, 72, 72]) \n",
      "encoder.layer2.0.downsample.0: torch.Size([1, 128, 72, 72]) \n",
      "encoder.layer2.0.downsample.1: torch.Size([1, 128, 72, 72]) \n",
      "encoder.layer2.0.downsample: torch.Size([1, 128, 72, 72]) \n",
      "encoder.layer2.0.relu: torch.Size([1, 128, 72, 72]) \n",
      "encoder.layer2.0: torch.Size([1, 128, 72, 72]) \n",
      "encoder.layer2.1.conv1: torch.Size([1, 128, 72, 72]) \n",
      "encoder.layer2.1.bn1: torch.Size([1, 128, 72, 72]) \n",
      "encoder.layer2.1.relu: torch.Size([1, 128, 72, 72]) \n",
      "encoder.layer2.1.conv2: torch.Size([1, 128, 72, 72]) \n",
      "encoder.layer2.1.bn2: torch.Size([1, 128, 72, 72]) \n",
      "encoder.layer2.1.relu: torch.Size([1, 128, 72, 72]) \n",
      "encoder.layer2.1: torch.Size([1, 128, 72, 72]) \n",
      "encoder.layer2: torch.Size([1, 128, 72, 72]) \n",
      "encoder.layer3.0.conv1: torch.Size([1, 256, 36, 36]) \n",
      "encoder.layer3.0.bn1: torch.Size([1, 256, 36, 36]) \n",
      "encoder.layer3.0.relu: torch.Size([1, 256, 36, 36]) \n",
      "encoder.layer3.0.conv2: torch.Size([1, 256, 36, 36]) \n",
      "encoder.layer3.0.bn2: torch.Size([1, 256, 36, 36]) \n",
      "encoder.layer3.0.downsample.0: torch.Size([1, 256, 36, 36]) \n",
      "encoder.layer3.0.downsample.1: torch.Size([1, 256, 36, 36]) \n",
      "encoder.layer3.0.downsample: torch.Size([1, 256, 36, 36]) \n",
      "encoder.layer3.0.relu: torch.Size([1, 256, 36, 36]) \n",
      "encoder.layer3.0: torch.Size([1, 256, 36, 36]) \n",
      "encoder.layer3.1.conv1: torch.Size([1, 256, 36, 36]) \n",
      "encoder.layer3.1.bn1: torch.Size([1, 256, 36, 36]) \n",
      "encoder.layer3.1.relu: torch.Size([1, 256, 36, 36]) \n",
      "encoder.layer3.1.conv2: torch.Size([1, 256, 36, 36]) \n",
      "encoder.layer3.1.bn2: torch.Size([1, 256, 36, 36]) \n",
      "encoder.layer3.1.relu: torch.Size([1, 256, 36, 36]) \n",
      "encoder.layer3.1: torch.Size([1, 256, 36, 36]) \n",
      "encoder.layer3: torch.Size([1, 256, 36, 36]) \n",
      "encoder.layer4.0.conv1: torch.Size([1, 512, 18, 18]) \n",
      "encoder.layer4.0.bn1: torch.Size([1, 512, 18, 18]) \n",
      "encoder.layer4.0.relu: torch.Size([1, 512, 18, 18]) \n",
      "encoder.layer4.0.conv2: torch.Size([1, 512, 18, 18]) \n",
      "encoder.layer4.0.bn2: torch.Size([1, 512, 18, 18]) \n",
      "encoder.layer4.0.downsample.0: torch.Size([1, 512, 18, 18]) \n",
      "encoder.layer4.0.downsample.1: torch.Size([1, 512, 18, 18]) \n",
      "encoder.layer4.0.downsample: torch.Size([1, 512, 18, 18]) \n",
      "encoder.layer4.0.relu: torch.Size([1, 512, 18, 18]) \n",
      "encoder.layer4.0: torch.Size([1, 512, 18, 18]) \n",
      "encoder.layer4.1.conv1: torch.Size([1, 512, 18, 18]) \n",
      "encoder.layer4.1.bn1: torch.Size([1, 512, 18, 18]) \n",
      "encoder.layer4.1.relu: torch.Size([1, 512, 18, 18]) \n",
      "encoder.layer4.1.conv2: torch.Size([1, 512, 18, 18]) \n",
      "encoder.layer4.1.bn2: torch.Size([1, 512, 18, 18]) \n",
      "encoder.layer4.1.relu: torch.Size([1, 512, 18, 18]) \n",
      "encoder.layer4.1: torch.Size([1, 512, 18, 18]) \n",
      "encoder.layer4: torch.Size([1, 512, 18, 18]) \n",
      "encoder: NO SHAPE\n",
      "decoder.center: torch.Size([1, 512, 18, 18]) \n",
      "decoder.blocks.0.attention1.attention: torch.Size([1, 768, 36, 36]) \n",
      "decoder.blocks.0.attention1: torch.Size([1, 768, 36, 36]) \n",
      "decoder.blocks.0.conv1.0: torch.Size([1, 256, 36, 36]) \n",
      "decoder.blocks.0.conv1.1: torch.Size([1, 256, 36, 36]) \n",
      "decoder.blocks.0.conv1.2: torch.Size([1, 256, 36, 36]) \n",
      "decoder.blocks.0.conv1: torch.Size([1, 256, 36, 36]) \n",
      "decoder.blocks.0.conv2.0: torch.Size([1, 256, 36, 36]) \n",
      "decoder.blocks.0.conv2.1: torch.Size([1, 256, 36, 36]) \n",
      "decoder.blocks.0.conv2.2: torch.Size([1, 256, 36, 36]) \n",
      "decoder.blocks.0.conv2: torch.Size([1, 256, 36, 36]) \n",
      "decoder.blocks.0.attention2.attention: torch.Size([1, 256, 36, 36]) \n",
      "decoder.blocks.0.attention2: torch.Size([1, 256, 36, 36]) \n",
      "decoder.blocks.0: torch.Size([1, 256, 36, 36]) \n",
      "decoder.blocks.1.attention1.attention: torch.Size([1, 384, 72, 72]) \n",
      "decoder.blocks.1.attention1: torch.Size([1, 384, 72, 72]) \n",
      "decoder.blocks.1.conv1.0: torch.Size([1, 128, 72, 72]) \n",
      "decoder.blocks.1.conv1.1: torch.Size([1, 128, 72, 72]) \n",
      "decoder.blocks.1.conv1.2: torch.Size([1, 128, 72, 72]) \n",
      "decoder.blocks.1.conv1: torch.Size([1, 128, 72, 72]) \n",
      "decoder.blocks.1.conv2.0: torch.Size([1, 128, 72, 72]) \n",
      "decoder.blocks.1.conv2.1: torch.Size([1, 128, 72, 72]) \n",
      "decoder.blocks.1.conv2.2: torch.Size([1, 128, 72, 72]) \n",
      "decoder.blocks.1.conv2: torch.Size([1, 128, 72, 72]) \n",
      "decoder.blocks.1.attention2.attention: torch.Size([1, 128, 72, 72]) \n",
      "decoder.blocks.1.attention2: torch.Size([1, 128, 72, 72]) \n",
      "decoder.blocks.1: torch.Size([1, 128, 72, 72]) \n",
      "decoder.blocks.2.attention1.attention: torch.Size([1, 192, 144, 144]) \n",
      "decoder.blocks.2.attention1: torch.Size([1, 192, 144, 144]) \n",
      "decoder.blocks.2.conv1.0: torch.Size([1, 64, 144, 144]) \n",
      "decoder.blocks.2.conv1.1: torch.Size([1, 64, 144, 144]) \n",
      "decoder.blocks.2.conv1.2: torch.Size([1, 64, 144, 144]) \n",
      "decoder.blocks.2.conv1: torch.Size([1, 64, 144, 144]) \n",
      "decoder.blocks.2.conv2.0: torch.Size([1, 64, 144, 144]) \n",
      "decoder.blocks.2.conv2.1: torch.Size([1, 64, 144, 144]) \n",
      "decoder.blocks.2.conv2.2: torch.Size([1, 64, 144, 144]) \n",
      "decoder.blocks.2.conv2: torch.Size([1, 64, 144, 144]) \n",
      "decoder.blocks.2.attention2.attention: torch.Size([1, 64, 144, 144]) \n",
      "decoder.blocks.2.attention2: torch.Size([1, 64, 144, 144]) \n",
      "decoder.blocks.2: torch.Size([1, 64, 144, 144]) \n",
      "decoder.blocks.3.attention1.attention: torch.Size([1, 128, 288, 288]) \n",
      "decoder.blocks.3.attention1: torch.Size([1, 128, 288, 288]) \n",
      "decoder.blocks.3.conv1.0: torch.Size([1, 32, 288, 288]) \n",
      "decoder.blocks.3.conv1.1: torch.Size([1, 32, 288, 288]) \n",
      "decoder.blocks.3.conv1.2: torch.Size([1, 32, 288, 288]) \n",
      "decoder.blocks.3.conv1: torch.Size([1, 32, 288, 288]) \n",
      "decoder.blocks.3.conv2.0: torch.Size([1, 32, 288, 288]) \n",
      "decoder.blocks.3.conv2.1: torch.Size([1, 32, 288, 288]) \n",
      "decoder.blocks.3.conv2.2: torch.Size([1, 32, 288, 288]) \n",
      "decoder.blocks.3.conv2: torch.Size([1, 32, 288, 288]) \n",
      "decoder.blocks.3.attention2.attention: torch.Size([1, 32, 288, 288]) \n",
      "decoder.blocks.3.attention2: torch.Size([1, 32, 288, 288]) \n",
      "decoder.blocks.3: torch.Size([1, 32, 288, 288]) \n",
      "decoder.blocks.4.conv1.0: torch.Size([1, 16, 576, 576]) \n",
      "decoder.blocks.4.conv1.1: torch.Size([1, 16, 576, 576]) \n",
      "decoder.blocks.4.conv1.2: torch.Size([1, 16, 576, 576]) \n",
      "decoder.blocks.4.conv1: torch.Size([1, 16, 576, 576]) \n",
      "decoder.blocks.4.conv2.0: torch.Size([1, 16, 576, 576]) \n",
      "decoder.blocks.4.conv2.1: torch.Size([1, 16, 576, 576]) \n",
      "decoder.blocks.4.conv2.2: torch.Size([1, 16, 576, 576]) \n",
      "decoder.blocks.4.conv2: torch.Size([1, 16, 576, 576]) \n",
      "decoder.blocks.4.attention2.attention: torch.Size([1, 16, 576, 576]) \n",
      "decoder.blocks.4.attention2: torch.Size([1, 16, 576, 576]) \n",
      "decoder.blocks.4: torch.Size([1, 16, 576, 576]) \n",
      "decoder: torch.Size([1, 16, 576, 576]) \n",
      "segmentation_head.0: torch.Size([1, 3, 576, 576]) \n",
      "segmentation_head.1: torch.Size([1, 3, 576, 576]) \n",
      "segmentation_head.2.activation: torch.Size([1, 3, 576, 576]) \n",
      "segmentation_head.2: torch.Size([1, 3, 576, 576]) \n",
      "segmentation_head: torch.Size([1, 3, 576, 576]) \n",
      ": torch.Size([1, 3, 576, 576]) \n"
     ]
    }
   ],
   "source": [
    "model_resnet18 = smp.Unet(\n",
    "    encoder_name=\"resnet18\",  # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",  # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=1,  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=3,  # model output channels (number of classes in your dataset)\n",
    ")\n",
    "verbose_model_resnet18 = VerboseExecution(model_resnet18)\n",
    "dummy_input = torch.randn(1, 1, 576, 576)\n",
    "\n",
    "_ = verbose_model_resnet18(dummy_input)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [
    {
     "data": {
      "text/plain": "145"
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(visualisation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [
    {
     "data": {
      "text/plain": "('encoder.conv1',\n tensor([[[[-1.9353e+00, -5.8528e+00, -2.7648e+00,  ..., -4.1500e+00,\n            -9.4235e-02,  1.4513e+00],\n           [-3.4575e+00, -3.1630e+00, -8.7083e-01,  ...,  3.1493e+00,\n             1.8155e+00,  1.5542e-01],\n           [ 2.4868e+00, -2.7244e+00,  3.3991e-01,  ...,  1.3450e+00,\n            -2.0022e+00,  5.1955e+00],\n           ...,\n           [-3.8173e+00,  5.5885e-02, -3.0199e+00,  ..., -9.1131e-01,\n            -2.1043e+00, -2.4944e+00],\n           [ 5.3915e+00,  3.3375e-02, -7.1988e+00,  ..., -3.0478e+00,\n            -2.3478e+00, -4.4943e+00],\n           [-1.3364e+00,  1.6976e+00,  5.3142e+00,  ...,  2.7189e+00,\n             2.6444e-02,  6.8614e+00]],\n \n          [[-3.1401e-01, -6.9064e-01, -2.4634e-01,  ..., -2.2497e+00,\n            -9.8976e-01, -2.6008e-01],\n           [ 2.2689e+00,  1.6058e+00, -8.8914e-01,  ...,  8.1021e-01,\n            -8.8663e-01, -1.6816e+00],\n           [-7.7532e-01, -1.4787e+00, -2.2148e+00,  ..., -3.5833e+00,\n            -2.7980e+00, -7.0000e-01],\n           ...,\n           [ 3.8883e-01,  1.7543e+00,  2.2517e+00,  ...,  2.1226e+00,\n             2.3267e+00, -7.3791e-01],\n           [-3.0655e+00, -3.5082e+00, -2.2483e+00,  ...,  3.7802e+00,\n             3.6560e+00,  1.3942e+00],\n           [-4.4685e-01,  2.2385e+00,  3.0826e+00,  ..., -1.1392e+00,\n             5.2659e-01,  2.1138e+00]],\n \n          [[ 8.8499e-08,  7.2481e-07, -1.3330e-07,  ..., -4.9276e-08,\n             2.0863e-06,  1.6532e-06],\n           [ 3.4390e-08,  1.2351e-06,  9.0243e-07,  ...,  2.0276e-06,\n             3.5103e-06,  9.3491e-07],\n           [-6.5174e-07,  1.1660e-06,  8.4787e-07,  ..., -3.9765e-06,\n            -3.2871e-07, -5.2664e-07],\n           ...,\n           [-7.7132e-07,  8.7838e-08,  2.5507e-07,  ...,  7.8816e-08,\n             4.8929e-07,  2.3620e-06],\n           [ 1.6201e-06,  4.6466e-07,  7.5076e-07,  ..., -1.8929e-06,\n            -3.3925e-06, -2.5062e-06],\n           [ 7.8797e-08,  5.7130e-07,  1.6705e-06,  ...,  8.5348e-07,\n             8.6870e-08, -3.4420e-07]],\n \n          ...,\n \n          [[ 8.4258e-01, -4.3457e-01,  3.8230e-01,  ...,  6.2420e-01,\n            -1.9277e-01,  8.7439e-01],\n           [ 7.3176e-01,  1.4396e+00,  3.2486e-01,  ...,  1.3941e+00,\n             3.6975e-02, -4.7593e-01],\n           [-2.3001e-01, -4.1861e-01,  1.0150e+00,  ..., -6.2263e-01,\n             8.5367e-01,  4.7591e-02],\n           ...,\n           [-3.3015e-01,  3.8766e-02,  1.3121e+00,  ..., -7.1115e-01,\n            -3.0210e-01,  1.3340e+00],\n           [-4.0319e-01,  5.2186e-01, -8.0322e-01,  ..., -3.3612e-01,\n             9.7607e-02,  4.9312e-01],\n           [-1.9467e-01,  1.0426e+00,  2.7183e-01,  ..., -7.8813e-01,\n            -6.3087e-01, -1.3258e-01]],\n \n          [[-2.1837e-01, -9.5345e-01, -1.3059e+00,  ...,  1.0542e-01,\n            -2.4855e-01,  2.8210e-01],\n           [ 2.0792e-01,  1.2292e-01,  4.8785e-01,  ..., -4.2097e-01,\n            -1.1922e+00, -3.3482e-01],\n           [-5.4583e-03, -4.3668e-01, -8.1444e-01,  ..., -1.4904e-01,\n            -6.2407e-01,  5.8396e-01],\n           ...,\n           [ 2.8451e-01,  1.0182e+00,  1.8608e+00,  ..., -3.4373e-01,\n            -4.2249e-01, -1.9232e+00],\n           [ 3.2635e-01,  2.1691e-01, -1.3987e-01,  ...,  9.1984e-01,\n             1.5341e+00,  3.8306e-01],\n           [-2.0912e-01, -8.9404e-01, -6.8042e-01,  ...,  4.4443e-01,\n             7.4256e-01,  9.6375e-03]],\n \n          [[-7.0923e-01, -6.9496e+00, -3.1344e+00,  ...,  4.6668e-01,\n            -4.1988e+00,  1.7952e+00],\n           [-9.3213e-01,  3.9738e+00,  6.0736e+00,  ...,  2.1573e+00,\n            -5.0243e-01,  4.6986e+00],\n           [ 1.3441e+00, -1.6410e+00, -3.9381e+00,  ..., -4.5371e+00,\n            -1.0774e+00, -3.2214e+00],\n           ...,\n           [ 1.2327e+00,  4.9734e+00,  1.3683e+00,  ..., -3.7443e+00,\n            -1.8412e+00, -4.0406e+00],\n           [ 3.0201e+00,  3.3634e+00, -4.8906e+00,  ...,  1.6295e+00,\n             4.2324e+00,  1.9483e+00],\n           [-2.4765e+00, -5.5148e+00,  7.6518e-01,  ...,  9.7511e-01,\n            -4.2799e+00, -6.2639e-01]]]], grad_fn=<MkldnnConvolutionBackward>))"
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualisation[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "VerboseExecution()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]:EXCEPTION encoder.conv1:'Conv2d' object has no attribute '__name__'\n",
      "[1]:EXCEPTION encoder.bn1:'BatchNorm2d' object has no attribute '__name__'\n",
      "[2]:EXCEPTION encoder.relu:'ReLU' object has no attribute '__name__'\n",
      "[3]:EXCEPTION encoder.maxpool:'MaxPool2d' object has no attribute '__name__'\n",
      "[4]:EXCEPTION encoder.layer1.0.conv1:'Conv2d' object has no attribute '__name__'\n",
      "[5]:EXCEPTION encoder.layer1.0.bn1:'BatchNorm2d' object has no attribute '__name__'\n",
      "[6]:EXCEPTION encoder.layer1.0.relu:'ReLU' object has no attribute '__name__'\n",
      "[7]:EXCEPTION encoder.layer1.0.conv2:'Conv2d' object has no attribute '__name__'\n",
      "[8]:EXCEPTION encoder.layer1.0.bn2:'BatchNorm2d' object has no attribute '__name__'\n",
      "[9]:EXCEPTION encoder.layer1.0.relu:'ReLU' object has no attribute '__name__'\n",
      "___encoder.layer1.0___\n",
      "[11]:EXCEPTION encoder.layer1.1.conv1:'Conv2d' object has no attribute '__name__'\n",
      "[12]:EXCEPTION encoder.layer1.1.bn1:'BatchNorm2d' object has no attribute '__name__'\n",
      "[13]:EXCEPTION encoder.layer1.1.relu:'ReLU' object has no attribute '__name__'\n",
      "[14]:EXCEPTION encoder.layer1.1.conv2:'Conv2d' object has no attribute '__name__'\n",
      "[15]:EXCEPTION encoder.layer1.1.bn2:'BatchNorm2d' object has no attribute '__name__'\n",
      "[16]:EXCEPTION encoder.layer1.1.relu:'ReLU' object has no attribute '__name__'\n",
      "___encoder.layer1.1___\n",
      "___encoder.layer1___\n",
      "[19]:EXCEPTION encoder.layer2.0.conv1:'Conv2d' object has no attribute '__name__'\n",
      "[20]:EXCEPTION encoder.layer2.0.bn1:'BatchNorm2d' object has no attribute '__name__'\n",
      "[21]:EXCEPTION encoder.layer2.0.relu:'ReLU' object has no attribute '__name__'\n",
      "[22]:EXCEPTION encoder.layer2.0.conv2:'Conv2d' object has no attribute '__name__'\n",
      "[23]:EXCEPTION encoder.layer2.0.bn2:'BatchNorm2d' object has no attribute '__name__'\n",
      "[24]:EXCEPTION encoder.layer2.0.downsample.0:'Conv2d' object has no attribute '__name__'\n",
      "[25]:EXCEPTION encoder.layer2.0.downsample.1:'BatchNorm2d' object has no attribute '__name__'\n",
      "___encoder.layer2.0.downsample___\n",
      "[27]:EXCEPTION encoder.layer2.0.relu:'ReLU' object has no attribute '__name__'\n",
      "___encoder.layer2.0___\n",
      "[29]:EXCEPTION encoder.layer2.1.conv1:'Conv2d' object has no attribute '__name__'\n",
      "[30]:EXCEPTION encoder.layer2.1.bn1:'BatchNorm2d' object has no attribute '__name__'\n",
      "[31]:EXCEPTION encoder.layer2.1.relu:'ReLU' object has no attribute '__name__'\n",
      "[32]:EXCEPTION encoder.layer2.1.conv2:'Conv2d' object has no attribute '__name__'\n",
      "[33]:EXCEPTION encoder.layer2.1.bn2:'BatchNorm2d' object has no attribute '__name__'\n",
      "[34]:EXCEPTION encoder.layer2.1.relu:'ReLU' object has no attribute '__name__'\n",
      "___encoder.layer2.1___\n",
      "___encoder.layer2___\n",
      "[37]:EXCEPTION encoder.layer3.0.conv1:'Conv2d' object has no attribute '__name__'\n",
      "[38]:EXCEPTION encoder.layer3.0.bn1:'BatchNorm2d' object has no attribute '__name__'\n",
      "[39]:EXCEPTION encoder.layer3.0.relu:'ReLU' object has no attribute '__name__'\n",
      "[40]:EXCEPTION encoder.layer3.0.conv2:'Conv2d' object has no attribute '__name__'\n",
      "[41]:EXCEPTION encoder.layer3.0.bn2:'BatchNorm2d' object has no attribute '__name__'\n",
      "[42]:EXCEPTION encoder.layer3.0.downsample.0:'Conv2d' object has no attribute '__name__'\n",
      "[43]:EXCEPTION encoder.layer3.0.downsample.1:'BatchNorm2d' object has no attribute '__name__'\n",
      "___encoder.layer3.0.downsample___\n",
      "[45]:EXCEPTION encoder.layer3.0.relu:'ReLU' object has no attribute '__name__'\n",
      "___encoder.layer3.0___\n",
      "[47]:EXCEPTION encoder.layer3.1.conv1:'Conv2d' object has no attribute '__name__'\n",
      "[48]:EXCEPTION encoder.layer3.1.bn1:'BatchNorm2d' object has no attribute '__name__'\n",
      "[49]:EXCEPTION encoder.layer3.1.relu:'ReLU' object has no attribute '__name__'\n",
      "[50]:EXCEPTION encoder.layer3.1.conv2:'Conv2d' object has no attribute '__name__'\n",
      "[51]:EXCEPTION encoder.layer3.1.bn2:'BatchNorm2d' object has no attribute '__name__'\n",
      "[52]:EXCEPTION encoder.layer3.1.relu:'ReLU' object has no attribute '__name__'\n",
      "___encoder.layer3.1___\n",
      "___encoder.layer3___\n",
      "[55]:EXCEPTION encoder.layer4.0.conv1:'Conv2d' object has no attribute '__name__'\n",
      "[56]:EXCEPTION encoder.layer4.0.bn1:'BatchNorm2d' object has no attribute '__name__'\n",
      "[57]:EXCEPTION encoder.layer4.0.relu:'ReLU' object has no attribute '__name__'\n",
      "[58]:EXCEPTION encoder.layer4.0.conv2:'Conv2d' object has no attribute '__name__'\n",
      "[59]:EXCEPTION encoder.layer4.0.bn2:'BatchNorm2d' object has no attribute '__name__'\n",
      "[60]:EXCEPTION encoder.layer4.0.downsample.0:'Conv2d' object has no attribute '__name__'\n",
      "[61]:EXCEPTION encoder.layer4.0.downsample.1:'BatchNorm2d' object has no attribute '__name__'\n",
      "___encoder.layer4.0.downsample___\n",
      "[63]:EXCEPTION encoder.layer4.0.relu:'ReLU' object has no attribute '__name__'\n",
      "___encoder.layer4.0___\n",
      "[65]:EXCEPTION encoder.layer4.1.conv1:'Conv2d' object has no attribute '__name__'\n",
      "[66]:EXCEPTION encoder.layer4.1.bn1:'BatchNorm2d' object has no attribute '__name__'\n",
      "[67]:EXCEPTION encoder.layer4.1.relu:'ReLU' object has no attribute '__name__'\n",
      "[68]:EXCEPTION encoder.layer4.1.conv2:'Conv2d' object has no attribute '__name__'\n",
      "[69]:EXCEPTION encoder.layer4.1.bn2:'BatchNorm2d' object has no attribute '__name__'\n",
      "[70]:EXCEPTION encoder.layer4.1.relu:'ReLU' object has no attribute '__name__'\n",
      "___encoder.layer4.1___\n",
      "___encoder.layer4___\n",
      "___encoder___\n",
      "[74]:EXCEPTION decoder.center:'Identity' object has no attribute '__name__'\n",
      "[75]:EXCEPTION decoder.blocks.0.attention1.attention:'Identity' object has no attribute '__name__'\n",
      "___decoder.blocks.0.attention1___\n",
      "[77]:EXCEPTION decoder.blocks.0.conv1.0:'Conv2d' object has no attribute '__name__'\n",
      "[78]:EXCEPTION decoder.blocks.0.conv1.1:'BatchNorm2d' object has no attribute '__name__'\n",
      "[79]:EXCEPTION decoder.blocks.0.conv1.2:'ReLU' object has no attribute '__name__'\n",
      "___decoder.blocks.0.conv1___\n",
      "[81]:EXCEPTION decoder.blocks.0.conv2.0:'Conv2d' object has no attribute '__name__'\n",
      "[82]:EXCEPTION decoder.blocks.0.conv2.1:'BatchNorm2d' object has no attribute '__name__'\n",
      "[83]:EXCEPTION decoder.blocks.0.conv2.2:'ReLU' object has no attribute '__name__'\n",
      "___decoder.blocks.0.conv2___\n",
      "[85]:EXCEPTION decoder.blocks.0.attention2.attention:'Identity' object has no attribute '__name__'\n",
      "___decoder.blocks.0.attention2___\n",
      "___decoder.blocks.0___\n",
      "[88]:EXCEPTION decoder.blocks.1.attention1.attention:'Identity' object has no attribute '__name__'\n",
      "___decoder.blocks.1.attention1___\n",
      "[90]:EXCEPTION decoder.blocks.1.conv1.0:'Conv2d' object has no attribute '__name__'\n",
      "[91]:EXCEPTION decoder.blocks.1.conv1.1:'BatchNorm2d' object has no attribute '__name__'\n",
      "[92]:EXCEPTION decoder.blocks.1.conv1.2:'ReLU' object has no attribute '__name__'\n",
      "___decoder.blocks.1.conv1___\n",
      "[94]:EXCEPTION decoder.blocks.1.conv2.0:'Conv2d' object has no attribute '__name__'\n",
      "[95]:EXCEPTION decoder.blocks.1.conv2.1:'BatchNorm2d' object has no attribute '__name__'\n",
      "[96]:EXCEPTION decoder.blocks.1.conv2.2:'ReLU' object has no attribute '__name__'\n",
      "___decoder.blocks.1.conv2___\n",
      "[98]:EXCEPTION decoder.blocks.1.attention2.attention:'Identity' object has no attribute '__name__'\n",
      "___decoder.blocks.1.attention2___\n",
      "___decoder.blocks.1___\n",
      "[101]:EXCEPTION decoder.blocks.2.attention1.attention:'Identity' object has no attribute '__name__'\n",
      "___decoder.blocks.2.attention1___\n",
      "[103]:EXCEPTION decoder.blocks.2.conv1.0:'Conv2d' object has no attribute '__name__'\n",
      "[104]:EXCEPTION decoder.blocks.2.conv1.1:'BatchNorm2d' object has no attribute '__name__'\n",
      "[105]:EXCEPTION decoder.blocks.2.conv1.2:'ReLU' object has no attribute '__name__'\n",
      "___decoder.blocks.2.conv1___\n",
      "[107]:EXCEPTION decoder.blocks.2.conv2.0:'Conv2d' object has no attribute '__name__'\n",
      "[108]:EXCEPTION decoder.blocks.2.conv2.1:'BatchNorm2d' object has no attribute '__name__'\n",
      "[109]:EXCEPTION decoder.blocks.2.conv2.2:'ReLU' object has no attribute '__name__'\n",
      "___decoder.blocks.2.conv2___\n",
      "[111]:EXCEPTION decoder.blocks.2.attention2.attention:'Identity' object has no attribute '__name__'\n",
      "___decoder.blocks.2.attention2___\n",
      "___decoder.blocks.2___\n",
      "[114]:EXCEPTION decoder.blocks.3.attention1.attention:'Identity' object has no attribute '__name__'\n",
      "___decoder.blocks.3.attention1___\n",
      "[116]:EXCEPTION decoder.blocks.3.conv1.0:'Conv2d' object has no attribute '__name__'\n",
      "[117]:EXCEPTION decoder.blocks.3.conv1.1:'BatchNorm2d' object has no attribute '__name__'\n",
      "[118]:EXCEPTION decoder.blocks.3.conv1.2:'ReLU' object has no attribute '__name__'\n",
      "___decoder.blocks.3.conv1___\n",
      "[120]:EXCEPTION decoder.blocks.3.conv2.0:'Conv2d' object has no attribute '__name__'\n",
      "[121]:EXCEPTION decoder.blocks.3.conv2.1:'BatchNorm2d' object has no attribute '__name__'\n",
      "[122]:EXCEPTION decoder.blocks.3.conv2.2:'ReLU' object has no attribute '__name__'\n",
      "___decoder.blocks.3.conv2___\n",
      "[124]:EXCEPTION decoder.blocks.3.attention2.attention:'Identity' object has no attribute '__name__'\n",
      "___decoder.blocks.3.attention2___\n",
      "___decoder.blocks.3___\n",
      "[127]:EXCEPTION decoder.blocks.4.conv1.0:'Conv2d' object has no attribute '__name__'\n",
      "[128]:EXCEPTION decoder.blocks.4.conv1.1:'BatchNorm2d' object has no attribute '__name__'\n",
      "[129]:EXCEPTION decoder.blocks.4.conv1.2:'ReLU' object has no attribute '__name__'\n",
      "___decoder.blocks.4.conv1___\n",
      "[131]:EXCEPTION decoder.blocks.4.conv2.0:'Conv2d' object has no attribute '__name__'\n",
      "[132]:EXCEPTION decoder.blocks.4.conv2.1:'BatchNorm2d' object has no attribute '__name__'\n",
      "[133]:EXCEPTION decoder.blocks.4.conv2.2:'ReLU' object has no attribute '__name__'\n",
      "___decoder.blocks.4.conv2___\n",
      "[135]:EXCEPTION decoder.blocks.4.attention2.attention:'Identity' object has no attribute '__name__'\n",
      "___decoder.blocks.4.attention2___\n",
      "___decoder.blocks.4___\n",
      "___decoder___\n",
      "[139]:EXCEPTION segmentation_head.0:'Conv2d' object has no attribute '__name__'\n",
      "[140]:EXCEPTION segmentation_head.1:'Identity' object has no attribute '__name__'\n",
      "[141]:EXCEPTION segmentation_head.2.activation:'Identity' object has no attribute '__name__'\n",
      "___segmentation_head.2___\n",
      "___segmentation_head___\n",
      "______\n"
     ]
    }
   ],
   "source": [
    "for ii, (name, mn,output) in enumerate(visualisation):\n",
    "    try:\n",
    "        if len(list(mn.children()))>0:\n",
    "            print(f'___{name}___')\n",
    "        else:\n",
    "            print(f\"[{ii}]:{name}<=>{mn.__name__}::{output.size()}:::{mn}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[{ii}]:EXCEPTION {name}:{e}\")\n",
    "#model_resnet18.encoder.conv1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.modules of Conv2dReLU(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")>\n",
      "<class 'method'>\n"
     ]
    }
   ],
   "source": [
    "dir(visualisation[110][1])\n",
    "print(visualisation[110][1].modules)\n",
    "print(type(visualisation[110][1].modules))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.nn.modules.conv.Conv2d"
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(visualisation[127][1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(list(visualisation[109][1].children()))\n",
    "print(list(visualisation[110][1].children()))\n",
    "print(list(visualisation[110][1].children()))\n",
    "print(list(visualisation[109][1].parent()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mod_names, mod_modules = [], []\n",
    "for mix, (name, module) in enumerate(model_resnet18.named_modules()):\n",
    "    mod_names.append(name)\n",
    "    mod_modules.append(module)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(list(visualisation[2][1].children()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', <class 'segmentation_models_pytorch.decoders.unet.model.Unet'>, False)\n",
      "('encoder', <class 'segmentation_models_pytorch.encoders.resnet.ResNetEncoder'>, False)\n",
      "('encoder.conv1', <class 'torch.nn.modules.conv.Conv2d'>, False)\n",
      "('encoder.bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>, False)\n",
      "('encoder.relu', <class 'torch.nn.modules.activation.ReLU'>, False)\n",
      "('encoder.maxpool', <class 'torch.nn.modules.pooling.MaxPool2d'>, False)\n",
      "('encoder.layer1', <class 'torch.nn.modules.container.Sequential'>, True)\n",
      "('encoder.layer1.0', <class 'torchvision.models.resnet.BasicBlock'>, False)\n",
      "('encoder.layer1.0.conv1', <class 'torch.nn.modules.conv.Conv2d'>, False)\n",
      "('encoder.layer1.0.bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>, False)\n"
     ]
    }
   ],
   "source": [
    "for ii in range(10):\n",
    "    print((mod_names[ii], type(mod_modules[ii]), isinstance(mod_modules[ii], nn.Sequential)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'segmentation_models_pytorch.decoders.unet.model.Unet'> ['apply', 'bfloat16', 'buffers', 'children', 'cpu', 'cuda', 'decoder', 'double', 'encoder', 'eval', 'float', 'forward', 'half', 'initialize', 'modules', 'name', 'parameters', 'predict', 'to', 'train', 'training', 'type']\n",
      "<class 'segmentation_models_pytorch.encoders.resnet.ResNetEncoder'> ['apply', 'bfloat16', 'bn1', 'buffers', 'children', 'conv1', 'cpu', 'cuda', 'dilation', 'double', 'eval', 'float', 'forward', 'groups', 'half', 'inplanes', 'layer1', 'layer2', 'layer3', 'layer4', 'maxpool', 'modules', 'parameters', 'relu', 'to', 'train', 'training', 'type']\n",
      "<class 'torch.nn.modules.conv.Conv2d'> ['apply', 'bfloat16', 'bias', 'buffers', 'children', 'cpu', 'cuda', 'dilation', 'double', 'eval', 'float', 'forward', 'groups', 'half', 'modules', 'padding', 'parameters', 'stride', 'to', 'train', 'training', 'transposed', 'type', 'weight']\n",
      "<class 'torch.nn.modules.container.Sequential'> ['apply', 'bfloat16', 'buffers', 'children', 'cpu', 'cuda', 'double', 'eval', 'float', 'forward', 'half', 'modules', 'parameters', 'to', 'train', 'training', 'type']\n",
      "<class 'torchvision.models.resnet.BasicBlock'> ['apply', 'bfloat16', 'bn1', 'bn2', 'buffers', 'children', 'conv1', 'conv2', 'cpu', 'cuda', 'double', 'downsample', 'eval', 'expansion', 'float', 'forward', 'half', 'modules', 'parameters', 'relu', 'stride', 'to', 'train', 'training', 'type']\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'> ['affine', 'apply', 'bfloat16', 'bias', 'buffers', 'children', 'cpu', 'cuda', 'double', 'eps', 'eval', 'float', 'forward', 'half', 'modules', 'momentum', 'parameters', 'to', 'train', 'training', 'type', 'weight']\n"
     ]
    }
   ],
   "source": [
    "for ii in [0, 1, 2, 6, 7, 9]:\n",
    "    print(type(mod_modules[ii]), [att for att in dir(mod_modules[ii]) if \"_\" not in att])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "par_names, par_parameters = [], []\n",
    "for mix, (name, parameters) in enumerate(model_resnet18.named_parameters()):\n",
    "    par_names.append(name)\n",
    "    par_parameters.append(parameters)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('encoder.conv1.weight', <class 'torch.nn.parameter.Parameter'>)\n",
      "('encoder.bn1.weight', <class 'torch.nn.parameter.Parameter'>)\n",
      "('encoder.bn1.bias', <class 'torch.nn.parameter.Parameter'>)\n",
      "('encoder.layer1.0.conv1.weight', <class 'torch.nn.parameter.Parameter'>)\n",
      "('encoder.layer1.0.bn1.weight', <class 'torch.nn.parameter.Parameter'>)\n",
      "('encoder.layer1.0.bn1.bias', <class 'torch.nn.parameter.Parameter'>)\n",
      "('encoder.layer1.0.conv2.weight', <class 'torch.nn.parameter.Parameter'>)\n",
      "('encoder.layer1.0.bn2.weight', <class 'torch.nn.parameter.Parameter'>)\n",
      "('encoder.layer1.0.bn2.bias', <class 'torch.nn.parameter.Parameter'>)\n",
      "('encoder.layer1.1.conv1.weight', <class 'torch.nn.parameter.Parameter'>)\n"
     ]
    }
   ],
   "source": [
    "for ii in range(10):\n",
    "    print((par_names[ii], type(par_parameters[ii])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'abs', 'acos', 'add', 'addbmm', 'addcdiv', 'addcmul', 'addmm', 'addmv', 'addr', 'all', 'allclose', 'angle', 'any', 'argmax', 'argmin', 'argsort', 'asin', 'atan', 'atan2', 'backward', 'baddbmm', 'bernoulli', 'bfloat16', 'bincount', 'bmm', 'bool', 'byte', 'ceil', 'char', 'cholesky', 'chunk', 'clamp', 'clone', 'coalesce', 'conj', 'contiguous', 'cos', 'cosh', 'cpu', 'cross', 'cuda', 'cummax', 'cummin', 'cumprod', 'cumsum', 'data', 'dequantize', 'det', 'detach', 'device', 'diag', 'diagflat', 'diagonal', 'digamma', 'dim', 'dist', 'div', 'dot', 'double', 'dtype', 'eig', 'eq', 'equal', 'erf', 'erfc', 'erfinv', 'exp', 'expand', 'expm1', 'fft', 'flatten', 'flip', 'float', 'floor', 'fmod', 'frac', 'gather', 'ge', 'geqrf', 'ger', 'grad', 'gt', 'half', 'hardshrink', 'histc', 'ifft', 'indices', 'int', 'inverse', 'irfft', 'isclose', 'item', 'kthvalue', 'layout', 'le', 'lerp', 'lgamma', 'log', 'log10', 'log1p', 'log2', 'logdet', 'logsumexp', 'long', 'lstsq', 'lt', 'lu', 'matmul', 'max', 'mean', 'median', 'min', 'mm', 'mode', 'mul', 'multinomial', 'mv', 'mvlgamma', 'name', 'names', 'narrow', 'ndim', 'ndimension', 'ne', 'neg', 'nelement', 'new', 'nonzero', 'norm', 'numel', 'numpy', 'orgqr', 'ormqr', 'permute', 'pinverse', 'polygamma', 'pow', 'prelu', 'prod', 'qr', 'qscheme', 'reciprocal', 'reinforce', 'relu', 'remainder', 'rename', 'renorm', 'repeat', 'reshape', 'resize', 'rfft', 'roll', 'rot90', 'round', 'rsqrt', 'scatter', 'select', 'shape', 'short', 'sigmoid', 'sign', 'sin', 'sinh', 'size', 'slogdet', 'smm', 'softmax', 'solve', 'sort', 'split', 'sqrt', 'square', 'squeeze', 'sspaddmm', 'std', 'stft', 'storage', 'stride', 'sub', 'sum', 'svd', 'symeig', 't', 'take', 'tan', 'tanh', 'to', 'tolist', 'topk', 'trace', 'transpose', 'tril', 'triu', 'trunc', 'type', 'unbind', 'unflatten', 'unfold', 'unique', 'unsqueeze', 'values', 'var', 'view', 'where']\n"
     ]
    }
   ],
   "source": [
    "print([att for att in dir(par_parameters[8]) if \"_\" not in att])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 92\n"
     ]
    }
   ],
   "source": [
    "print(len(mod_names),len(par_names))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['encoder.conv1.weight', 'encoder.bn1.weight', 'encoder.bn1.bias', 'encoder.layer1.0.conv1.weight', 'encoder.layer1.0.bn1.weight', 'encoder.layer1.0.bn1.bias']\n",
      "['', 'encoder', 'encoder.conv1', 'encoder.bn1', 'encoder.relu', 'encoder.maxpool', 'encoder.layer1', 'encoder.layer1.0', 'encoder.layer1.0.conv1', 'encoder.layer1.0.bn1']\n"
     ]
    }
   ],
   "source": [
    "print(par_names[0:6])\n",
    "print(mod_names[0:10])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "data": {
      "text/plain": "235"
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "418-183"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 64, 144, 144])"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_resnet18.encoder.maxpool(model_resnet18.encoder.conv1(torch.randn(1, 1, 576, 576))).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_resnet18.encoder.conv1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "dummy_input = Variable(torch.randn(1, 1, 576, 576))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "torch.onnx.export(model_resnet18, dummy_input, os.path.join(model_dir, \"unet_resnet18_not_trained.onnx\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___\n",
      "[Unet(\n",
      "  (encoder): ResNetEncoder(\n",
      "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): UnetDecoder(\n",
      "    (center): Identity()\n",
      "    (blocks): ModuleList(\n",
      "      (0): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (4): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (segmentation_head): SegmentationHead(\n",
      "    (0): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Identity()\n",
      "    (2): Activation(\n",
      "      (activation): Identity()\n",
      "    )\n",
      "  )\n",
      "), ResNetEncoder(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "), Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False), Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "), BasicBlock(\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), BasicBlock(\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "), BasicBlock(\n",
      "  (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "), Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Sequential(\n",
      "  (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "), Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), BasicBlock(\n",
      "  (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "), BasicBlock(\n",
      "  (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "), Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Sequential(\n",
      "  (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "), Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), BasicBlock(\n",
      "  (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "), BasicBlock(\n",
      "  (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "), Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Sequential(\n",
      "  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "), Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), BasicBlock(\n",
      "  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), UnetDecoder(\n",
      "  (center): Identity()\n",
      "  (blocks): ModuleList(\n",
      "    (0): DecoderBlock(\n",
      "      (conv1): Conv2dReLU(\n",
      "        (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (attention1): Attention(\n",
      "        (attention): Identity()\n",
      "      )\n",
      "      (conv2): Conv2dReLU(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (attention2): Attention(\n",
      "        (attention): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): DecoderBlock(\n",
      "      (conv1): Conv2dReLU(\n",
      "        (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (attention1): Attention(\n",
      "        (attention): Identity()\n",
      "      )\n",
      "      (conv2): Conv2dReLU(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (attention2): Attention(\n",
      "        (attention): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): DecoderBlock(\n",
      "      (conv1): Conv2dReLU(\n",
      "        (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (attention1): Attention(\n",
      "        (attention): Identity()\n",
      "      )\n",
      "      (conv2): Conv2dReLU(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (attention2): Attention(\n",
      "        (attention): Identity()\n",
      "      )\n",
      "    )\n",
      "    (3): DecoderBlock(\n",
      "      (conv1): Conv2dReLU(\n",
      "        (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (attention1): Attention(\n",
      "        (attention): Identity()\n",
      "      )\n",
      "      (conv2): Conv2dReLU(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (attention2): Attention(\n",
      "        (attention): Identity()\n",
      "      )\n",
      "    )\n",
      "    (4): DecoderBlock(\n",
      "      (conv1): Conv2dReLU(\n",
      "        (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (attention1): Attention(\n",
      "        (attention): Identity()\n",
      "      )\n",
      "      (conv2): Conv2dReLU(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (attention2): Attention(\n",
      "        (attention): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "), Identity(), ModuleList(\n",
      "  (0): DecoderBlock(\n",
      "    (conv1): Conv2dReLU(\n",
      "      (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (attention1): Attention(\n",
      "      (attention): Identity()\n",
      "    )\n",
      "    (conv2): Conv2dReLU(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (attention2): Attention(\n",
      "      (attention): Identity()\n",
      "    )\n",
      "  )\n",
      "  (1): DecoderBlock(\n",
      "    (conv1): Conv2dReLU(\n",
      "      (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (attention1): Attention(\n",
      "      (attention): Identity()\n",
      "    )\n",
      "    (conv2): Conv2dReLU(\n",
      "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (attention2): Attention(\n",
      "      (attention): Identity()\n",
      "    )\n",
      "  )\n",
      "  (2): DecoderBlock(\n",
      "    (conv1): Conv2dReLU(\n",
      "      (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (attention1): Attention(\n",
      "      (attention): Identity()\n",
      "    )\n",
      "    (conv2): Conv2dReLU(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (attention2): Attention(\n",
      "      (attention): Identity()\n",
      "    )\n",
      "  )\n",
      "  (3): DecoderBlock(\n",
      "    (conv1): Conv2dReLU(\n",
      "      (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (attention1): Attention(\n",
      "      (attention): Identity()\n",
      "    )\n",
      "    (conv2): Conv2dReLU(\n",
      "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (attention2): Attention(\n",
      "      (attention): Identity()\n",
      "    )\n",
      "  )\n",
      "  (4): DecoderBlock(\n",
      "    (conv1): Conv2dReLU(\n",
      "      (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (attention1): Attention(\n",
      "      (attention): Identity()\n",
      "    )\n",
      "    (conv2): Conv2dReLU(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (attention2): Attention(\n",
      "      (attention): Identity()\n",
      "    )\n",
      "  )\n",
      "), DecoderBlock(\n",
      "  (conv1): Conv2dReLU(\n",
      "    (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (attention1): Attention(\n",
      "    (attention): Identity()\n",
      "  )\n",
      "  (conv2): Conv2dReLU(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (attention2): Attention(\n",
      "    (attention): Identity()\n",
      "  )\n",
      "), Conv2dReLU(\n",
      "  (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "), Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), Attention(\n",
      "  (attention): Identity()\n",
      "), Identity(), Conv2dReLU(\n",
      "  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), Attention(\n",
      "  (attention): Identity()\n",
      "), Identity(), DecoderBlock(\n",
      "  (conv1): Conv2dReLU(\n",
      "    (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (attention1): Attention(\n",
      "    (attention): Identity()\n",
      "  )\n",
      "  (conv2): Conv2dReLU(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (attention2): Attention(\n",
      "    (attention): Identity()\n",
      "  )\n",
      "), Conv2dReLU(\n",
      "  (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "), Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), Attention(\n",
      "  (attention): Identity()\n",
      "), Identity(), Conv2dReLU(\n",
      "  (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), Attention(\n",
      "  (attention): Identity()\n",
      "), Identity(), DecoderBlock(\n",
      "  (conv1): Conv2dReLU(\n",
      "    (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (attention1): Attention(\n",
      "    (attention): Identity()\n",
      "  )\n",
      "  (conv2): Conv2dReLU(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (attention2): Attention(\n",
      "    (attention): Identity()\n",
      "  )\n",
      "), Conv2dReLU(\n",
      "  (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "), Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), Attention(\n",
      "  (attention): Identity()\n",
      "), Identity(), Conv2dReLU(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), Attention(\n",
      "  (attention): Identity()\n",
      "), Identity(), DecoderBlock(\n",
      "  (conv1): Conv2dReLU(\n",
      "    (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (attention1): Attention(\n",
      "    (attention): Identity()\n",
      "  )\n",
      "  (conv2): Conv2dReLU(\n",
      "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (attention2): Attention(\n",
      "    (attention): Identity()\n",
      "  )\n",
      "), Conv2dReLU(\n",
      "  (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "), Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), Attention(\n",
      "  (attention): Identity()\n",
      "), Identity(), Conv2dReLU(\n",
      "  (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "), Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), Attention(\n",
      "  (attention): Identity()\n",
      "), Identity(), DecoderBlock(\n",
      "  (conv1): Conv2dReLU(\n",
      "    (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (attention1): Attention(\n",
      "    (attention): Identity()\n",
      "  )\n",
      "  (conv2): Conv2dReLU(\n",
      "    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (attention2): Attention(\n",
      "    (attention): Identity()\n",
      "  )\n",
      "), Conv2dReLU(\n",
      "  (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "), Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), Attention(\n",
      "  (attention): Identity()\n",
      "), Identity(), Conv2dReLU(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "), Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), Attention(\n",
      "  (attention): Identity()\n",
      "), Identity(), SegmentationHead(\n",
      "  (0): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): Identity()\n",
      "  (2): Activation(\n",
      "    (activation): Identity()\n",
      "  )\n",
      "), Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), Identity(), Activation(\n",
      "  (activation): Identity()\n",
      "), Identity()]\n"
     ]
    }
   ],
   "source": [
    "print(\"___\")\n",
    "print(modules)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "torch.save(modules[1], os.path.join(model_dir, \"unet_resnet18_encoder.pth\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model_resnet18, os.path.join(model_dir, \"unet_resnet18_non_trained.pth\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "======================================================================\nLayer (type:depth-idx)                        Param #\n======================================================================\nUnet                                          --\n├─ResNetEncoder: 1-1                          --\n│    └─Conv2d: 2-1                            3,136\n│    └─BatchNorm2d: 2-2                       128\n│    └─ReLU: 2-3                              --\n│    └─MaxPool2d: 2-4                         --\n│    └─Sequential: 2-5                        --\n│    │    └─BasicBlock: 3-1                   73,984\n│    │    └─BasicBlock: 3-2                   73,984\n│    └─Sequential: 2-6                        --\n│    │    └─BasicBlock: 3-3                   230,144\n│    │    └─BasicBlock: 3-4                   295,424\n│    └─Sequential: 2-7                        --\n│    │    └─BasicBlock: 3-5                   919,040\n│    │    └─BasicBlock: 3-6                   1,180,672\n│    └─Sequential: 2-8                        --\n│    │    └─BasicBlock: 3-7                   3,673,088\n│    │    └─BasicBlock: 3-8                   4,720,640\n├─UnetDecoder: 1-2                            --\n│    └─Identity: 2-9                          --\n│    └─ModuleList: 2-10                       --\n│    │    └─DecoderBlock: 3-9                 2,360,320\n│    │    └─DecoderBlock: 3-10                590,336\n│    │    └─DecoderBlock: 3-11                147,712\n│    │    └─DecoderBlock: 3-12                46,208\n│    │    └─DecoderBlock: 3-13                6,976\n├─SegmentationHead: 1-3                       --\n│    └─Conv2d: 2-11                           435\n│    └─Identity: 2-12                         --\n│    └─Activation: 2-13                       --\n│    │    └─Identity: 3-14                    --\n======================================================================\nTotal params: 14,322,227\nTrainable params: 14,322,227\nNon-trainable params: 0\n======================================================================"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "channels= 3\n",
    "#summary(model_resnet18, input_size=(batch_size,channels, 572, 572))\n",
    "summary(model_resnet18)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "torch.save(model_resnet18, os.path.join(model_dir, \"unet_resnet18_non_trained.pth\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet(\n",
      "  (encoder): ResNetEncoder(\n",
      "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): UnetDecoder(\n",
      "    (center): Identity()\n",
      "    (blocks): ModuleList(\n",
      "      (0): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (4): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (segmentation_head): SegmentationHead(\n",
      "    (0): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Identity()\n",
      "    (2): Activation(\n",
      "      (activation): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_resnet18)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "model_vgg = smp.Unet(\n",
    "    encoder_name=\"vgg16\",  # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",  # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=1,  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=3,  # model output channels (number of classes in your dataset)\n",
    ")\n",
    "\n",
    "torch.save(model_vgg, os.path.join(model_dir, \"unet_vgg16_non_trained.pth\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet(\n",
      "  (encoder): VGGEncoder(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): ReLU(inplace=True)\n",
      "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (13): ReLU(inplace=True)\n",
      "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (15): ReLU(inplace=True)\n",
      "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (18): ReLU(inplace=True)\n",
      "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (20): ReLU(inplace=True)\n",
      "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (22): ReLU(inplace=True)\n",
      "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (25): ReLU(inplace=True)\n",
      "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (27): ReLU(inplace=True)\n",
      "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (29): ReLU(inplace=True)\n",
      "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  )\n",
      "  (decoder): UnetDecoder(\n",
      "    (center): CenterBlock(\n",
      "      (0): Conv2dReLU(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dReLU(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (blocks): ModuleList(\n",
      "      (0): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(768, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(192, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (4): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (segmentation_head): SegmentationHead(\n",
      "    (0): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Identity()\n",
      "    (2): Activation(\n",
      "      (activation): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_vgg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__annotations__', '__call__', '__class__', '__constants__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slotnames__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_buffers', '_conv_forward', '_forward_hooks', '_forward_pre_hooks', '_get_name', '_load_from_state_dict', '_load_state_dict_pre_hooks', '_modules', '_named_members', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_reversed_padding_repeated_twice', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_version', 'add_module', 'apply', 'bfloat16', 'bias', 'buffers', 'children', 'cpu', 'cuda', 'dilation', 'double', 'dump_patches', 'eval', 'extra_repr', 'float', 'forward', 'groups', 'half', 'in_channels', 'kernel_size', 'load_state_dict', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'out_channels', 'output_padding', 'padding', 'padding_mode', 'parameters', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_parameter', 'requires_grad_', 'reset_parameters', 'share_memory', 'state_dict', 'stride', 'to', 'train', 'training', 'transposed', 'type', 'weight', 'zero_grad']\n",
      "<bound method Module.state_dict of Conv2d(3, 10, kernel_size=(2, 2), stride=(2, 2))>\n",
      "Conv2d <class 'torch.nn.modules.conv.Conv2d'> torch.Size([1, 3, 8, 8]) torch.Size([1, 10, 4, 4])\n",
      "['__call__', '__class__', '__constants__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slotnames__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_buffers', '_forward_hooks', '_forward_pre_hooks', '_get_name', '_load_from_state_dict', '_load_state_dict_pre_hooks', '_modules', '_named_members', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_version', 'add_module', 'apply', 'bfloat16', 'buffers', 'children', 'cpu', 'cuda', 'double', 'dump_patches', 'eval', 'extra_repr', 'float', 'forward', 'half', 'inplace', 'load_state_dict', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'parameters', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_parameter', 'requires_grad_', 'share_memory', 'state_dict', 'to', 'train', 'training', 'type', 'zero_grad']\n",
      "<bound method Module.state_dict of ReLU()>\n",
      "ReLU <class 'torch.nn.modules.activation.ReLU'> torch.Size([1, 10, 4, 4]) torch.Size([1, 10, 4, 4])\n",
      "['__call__', '__class__', '__constants__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_buffers', '_forward_hooks', '_forward_pre_hooks', '_get_name', '_load_from_state_dict', '_load_state_dict_pre_hooks', '_modules', '_named_members', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_version', 'add_module', 'apply', 'bfloat16', 'bias', 'buffers', 'children', 'cpu', 'cuda', 'double', 'dump_patches', 'eval', 'extra_repr', 'float', 'forward', 'half', 'in_features', 'load_state_dict', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'out_features', 'parameters', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_parameter', 'requires_grad_', 'reset_parameters', 'share_memory', 'state_dict', 'to', 'train', 'training', 'type', 'weight', 'zero_grad']\n",
      "<bound method Module.state_dict of Linear(in_features=160, out_features=5, bias=True)>\n",
      "Linear <class 'torch.nn.modules.linear.Linear'> torch.Size([160]) torch.Size([5])\n",
      "['__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_buffers', '_forward_hooks', '_forward_pre_hooks', '_get_name', '_load_from_state_dict', '_load_state_dict_pre_hooks', '_modules', '_named_members', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_version', 'add_module', 'apply', 'bfloat16', 'buffers', 'children', 'conv', 'cpu', 'cuda', 'double', 'dump_patches', 'eval', 'extra_repr', 'fc1', 'flatten', 'float', 'forward', 'half', 'load_state_dict', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'parameters', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_parameter', 'relu', 'requires_grad_', 'share_memory', 'state_dict', 'to', 'train', 'training', 'type', 'zero_grad']\n",
      "<bound method Module.state_dict of myNet(\n",
      "  (conv): Conv2d(3, 10, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (relu): ReLU()\n",
      "  (fc1): Linear(in_features=160, out_features=5, bias=True)\n",
      ")>\n",
      "myNet <class '__main__.myNet'> torch.Size([1, 3, 8, 8]) torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class myNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv = nn.Conv2d(3,10,2, stride = 2)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.flatten = lambda x: x.view(-1)\n",
    "    self.fc1 = nn.Linear(160,5)\n",
    "  def forward(self, x):\n",
    "    x = self.relu(self.conv(x))\n",
    "    return self.fc1(self.flatten(x))\n",
    "\n",
    "net = myNet()\n",
    "\n",
    "def hook_forward_fn(m, i, o):\n",
    "    #print(x)\n",
    "    print(dir(m))\n",
    "    print(m.state_dict)\n",
    "\n",
    "    #print(m.__annotations__)\n",
    "\n",
    "    print('_' if not hasattr(m, '_get_name') else m._get_name(), type(m), i[0].size(), o.size())\n",
    "\n",
    "for m in net.named_modules():\n",
    "    m[1].register_forward_hook(hook_forward_fn)\n",
    "#net.conv.register_forward_hook(hook_forward_fn)\n",
    "\n",
    "inp = torch.randn(1,3,8,8)\n",
    "out = net(inp)\n",
    "\n",
    "(1 - out.mean()).backward()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "nv_torch1.5",
   "language": "python",
   "display_name": "nv_torch1.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}